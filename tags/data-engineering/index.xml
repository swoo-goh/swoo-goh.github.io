<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LogicFirstDataEngineer – Data Engineering</title><link>https://swoo-goh.github.io/tags/data-engineering/</link><description>Recent content in Data Engineering on LogicFirstDataEngineer</description><generator>Hugo -- gohugo.io</generator><language>ko-KR</language><lastBuildDate>Fri, 12 Dec 2025 09:00:00 +0900</lastBuildDate><atom:link href="https://swoo-goh.github.io/tags/data-engineering/index.xml" rel="self" type="application/rss+xml"/><item><title>클라우드 비용 효율화 : 지속 가능한 성장을 위한 3가지 대수술: 기술적 최적화가 경영의 효율성으로 이어지는 길</title><link>https://swoo-goh.github.io/blog/data_engineering/cloud_cost_optimization2/</link><pubDate>Fri, 12 Dec 2025 09:00:00 +0900</pubDate><guid>https://swoo-goh.github.io/blog/data_engineering/cloud_cost_optimization2/</guid><description>
&lt;img src="../images/top_banner.png" width="100%"&gt;
&lt;h4&gt;1. Intro: &amp;lsquo;약속된 낙원&amp;rsquo;은 없었다 (The Cloud Paradox)&lt;span class="hx:absolute hx:-mt-20" id="1-intro-약속된-낙원은-없었다-the-cloud-paradox"&gt;&lt;/span&gt;
&lt;a href="#1-intro-%ec%95%bd%ec%86%8d%eb%90%9c-%eb%82%99%ec%9b%90%ec%9d%80-%ec%97%86%ec%97%88%eb%8b%a4-the-cloud-paradox" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;수년 전, 우리가 안정적인 온프레미스(On-Premise) 환경을 뒤로하고 대대적인 &amp;lsquo;클라우드 마이그레이션&amp;rsquo;을 감행했던 이유는 명확했습니다.&lt;/p&gt;
&lt;p&gt;첫째는 **인프라 비용의 획기적 절감(Cost Efficiency)**이었고, 둘째는 하드웨어 관리에서 해방되어 **전문적인 서비스 관리(Managed Service)**를 받기 위함이었습니다.&lt;/p&gt;
&lt;p&gt;하지만 2025년 현재, 우리가 받아든 성적표는 어떻습니까? **&amp;lsquo;비용 절감&amp;rsquo;**은커녕 예측 불가능한 변동비 폭탄을 맞고 있으며, **&amp;lsquo;관리의 편의성&amp;rsquo;**은 복잡해진 아키텍처와 청구서 분석이라는 새로운 관리 비용으로 치환되었습니다. 우리는 &amp;lsquo;하드웨어&amp;rsquo;라는 짐을 내려놓은 대신, &amp;lsquo;비용&amp;rsquo;이라는 더 무거운 짐을 지게 되었습니다.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;그렇다면 답은 다시 온프레미스로의 회귀일까요?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;결단코 아닙니다. 2025년의 비즈니스 환경에서 클라우드를 포기하는 것은, 무기를 버리고 전장에 나가는 것과 같습니다. 우리가 비싼 수업료를 내면서도 클라우드에 머물러야 하는 이유는 여전히 유효합니다.&lt;/p&gt;
&lt;p&gt;글로벌 확장과 민첩성 (Globalization &amp;amp; Speed): 한국에서 버튼 하나로 전 세계 리전(Region)에 서비스를 배포하고, 새로운 AI 모델의 PoC/BMT를 즉시 수행할 수 있는 속도는 물리 서버가 따라올 수 없습니다.&lt;/p&gt;
&lt;p&gt;탄력적 대응 (Scalability): 트래픽이 폭주하는 &amp;lsquo;이벤트 데이&amp;rsquo;에만 서버를 늘렸다가 줄이는 유연성은, 유휴 자원(Idle Resource) 낭비를 막는 유일한 길입니다.&lt;/p&gt;
&lt;p&gt;엔터프라이즈급 보안 (Security): 올해 발생한 연쇄적인 보안 사고들을 보십시오. 천문학적인 예산과 최고의 인재를 보유한 &amp;lsquo;빅테크(Big Tech)&amp;rsquo; 기업들의 보안망조차 속수무책으로 뚫렸습니다. 이는 개별 기업이 자체적으로 구축한 온프레미스 방어막으로는 고도화된 위협을 막아내는 데 한계가 있음을 시사합니다. 오히려 클라우드 벤더의 거대한 &amp;lsquo;보안 우산(Security Umbrella)&amp;rsquo; 아래에서 글로벌 표준을 방어하는 것이 가장 현실적인 생존 전략입니다.&lt;/p&gt;
&lt;p&gt;문제는 &amp;lsquo;클라우드&amp;rsquo;라는 도구 자체가 아닙니다. 문제는 그것을 사용하는 우리의 &amp;lsquo;방만함&amp;rsquo;입니다.&lt;/p&gt;
&lt;p&gt;편리한 관리형 서비스 뒤에는 **&amp;lsquo;벤더 종속(Lock-in)&amp;rsquo;**이라는 족쇄가 기다리고 있고, 무심코 설계한 아키텍처 사이로 **&amp;lsquo;데이터 전송료(Egress Fee)&amp;rsquo;**와 **&amp;lsquo;API 호출 비용&amp;rsquo;**이 새어 나갑니다.&lt;/p&gt;
&lt;p&gt;가장 혁신적인 도구를 가장 비효율적인 방식(Legacy)으로 사용하고 있기에 비용 폭탄을 맞는 것입니다. 이제는 인정해야 합니다. 단순히 클라우드로 옮기는 것만으로는 혁신이 완성되지 않습니다. 무분별한 확장(Expansion)을 멈추고, **정밀한 수술(Surgery)**을 통해 시스템의 체질을 바꿔야 할 때입니다.&lt;/p&gt;
&lt;img src="../images/cloud_cost_optimization_21.jpg" width="100%"&gt;
&lt;h4&gt;Surgery 1. 스토리지의 혁신 : &amp;ldquo;적재(Store)에서 관리(Manage)로&amp;rdquo;&lt;span class="hx:absolute hx:-mt-20" id="surgery-1-스토리지의-혁신--적재store에서-관리manage로"&gt;&lt;/span&gt;
&lt;a href="#surgery-1-%ec%8a%a4%ed%86%a0%eb%a6%ac%ec%a7%80%ec%9d%98-%ed%98%81%ec%8b%a0--%ec%a0%81%ec%9e%acstore%ec%97%90%ec%84%9c-%ea%b4%80%eb%a6%acmanage%eb%a1%9c" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;[증상: The Data Swamp]&lt;/strong&gt; 많은 기업이 데이터 레이크(Data Lake)를 구축했지만, 실상은 데이터가 중복되어 쌓여만 가는 &amp;lsquo;데이터 늪&amp;rsquo;에 가깝습니다. v1, v2, final, real_final&amp;hellip; 수정과 삭제가 어려운 기존 파일 시스템의 한계로 인해, 불필요한 스토리지 비용이 눈덩이처럼 불어나고 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[처방: Modern Table Format 도입]&lt;/strong&gt; Apache Iceberg, Hudi, Delta Lake와 같은 현대적인 테이블 포맷은 스토리지 관리의 패러다임을 바꿉니다.&lt;/p&gt;
&lt;p&gt;단일 소스(Single Source): 데이터를 물리적으로 복제하지 않고, 논리적 스냅샷(Snapshot)으로 버전을 관리하여 스토리지 낭비를 최소화합니다.&lt;/p&gt;
&lt;p&gt;Time Travel &amp;amp; ACID: 과거 시점 조회와 완벽한 트랜잭션 지원으로, 데이터 정합성을 맞추기 위해 파티션을 통째로 엎는 비효율을 제거합니다.&lt;/p&gt;
&lt;p&gt;탈(脫) 벤더: 특정 클라우드 벤더의 포맷이 아닌 오픈 포맷을 사용함으로써, 향후 발생할 수 있는 데이터 인질극(Lock-in)에서 자유로워집니다.&lt;/p&gt;
&lt;h4&gt;Surgery 2. 컴퓨팅의 최적화 : &amp;ldquo;목적에 부합하는 엔진(Fit for Purpose)&amp;rdquo;&lt;span class="hx:absolute hx:-mt-20" id="surgery-2-컴퓨팅의-최적화--목적에-부합하는-엔진fit-for-purpose"&gt;&lt;/span&gt;
&lt;a href="#surgery-2-%ec%bb%b4%ed%93%a8%ed%8c%85%ec%9d%98-%ec%b5%9c%ec%a0%81%ed%99%94--%eb%aa%a9%ec%a0%81%ec%97%90-%eb%b6%80%ed%95%a9%ed%95%98%eb%8a%94-%ec%97%94%ec%a7%84fit-for-purpose" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;[증상: One Size Fits All]&lt;/strong&gt; 100GB 배치도 Spark, 10GB 조회도 Spark, 1TB ETL도 Spark. 특정 엔진 하나로 모든 데이터 처리를 수행하려는 &amp;lsquo;만능주의&amp;rsquo;가 만연해 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[처방: Layered Engine Architecture]&lt;/strong&gt; 우리는 먼저 인정해야 합니다. 시장에 나와 있는 Spark, Tez, Trino 등은 모두 각자의 영역에서 최고의 성능을 내도록 설계된 **&amp;lsquo;엔지니어링의 명작&amp;rsquo;**들입니다. 아키텍트의 역할은 이들의 고유한 설계 철학(Philosophy)을 이해하고 적재적소에 배치하는 것입니다.&lt;/p&gt;
&lt;p&gt;Heavy Batch (Tez): 대용량 데이터의 안정적 처리가 필요한 ETL 작업에는, 화려함보다 **&amp;lsquo;경제성&amp;rsquo;**과 **&amp;lsquo;정밀 제어&amp;rsquo;**가 중요합니다. 2,000억 건의 데이터를 디스크 기반으로 묵묵히 처리해 내는 Tez의 &amp;lsquo;지구력&amp;rsquo;은 대규모 배치 처리에 가장 적합한 덕목입니다.&lt;/p&gt;
&lt;p&gt;Ad-hoc Analysis (Trino): 빠른 의사결정이 필요한 분석 업무에는, 쿼리 응답 속도(Latency)에 목숨을 건 Trino가 최고의 파트너입니다.&lt;/p&gt;
&lt;p&gt;Advanced Analytics (Spark): 머신러닝(ML)이나 스트리밍처럼 메모리를 많이 쓰더라도 빠른 반복 계산이 필요한 영역에서는, Spark의 강력한 퍼포먼스가 빛을 발합니다.&lt;/p&gt;
&lt;p&gt;모든 엔진은 각자의 무대에서는 주인공입니다. 아키텍트는 그들을 한 무대에 억지로 구겨 넣는 것이 아니라, 각자가 가장 빛날 수 있는 무대(Layer)를 만들어주는 연출가여야 합니다.&lt;/p&gt;
&lt;h4&gt;Surgery 3. 인재의 재정의 : &amp;ldquo;시스템과 교육의 혁신&amp;rdquo;&lt;span class="hx:absolute hx:-mt-20" id="surgery-3-인재의-재정의--시스템과-교육의-혁신"&gt;&lt;/span&gt;
&lt;a href="#surgery-3-%ec%9d%b8%ec%9e%ac%ec%9d%98-%ec%9e%ac%ec%a0%95%ec%9d%98--%ec%8b%9c%ec%8a%a4%ed%85%9c%ea%b3%bc-%ea%b5%90%ec%9c%a1%ec%9d%98-%ed%98%81%ec%8b%a0" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;[진단 1: 스펙 인플레이션과 &amp;lsquo;게으른 검증&amp;rsquo;]&lt;/strong&gt; 우리는 종종 &amp;ldquo;스펙은 화려한데 일은 못 하는 엔지니어&amp;quot;를 마주합니다. 하지만 이것은 지원자들의 잘못이 아닙니다. 글로벌 빅테크의 채용 방식을 껍데기만 베껴 온 기업들의 &amp;lsquo;게으른 검증 시스템&amp;rsquo;이 만든 비극입니다.&lt;/p&gt;
&lt;p&gt;많은 기업이 빅테크가 &amp;lsquo;왜&amp;rsquo; 그런 면접을 보는지 근본적인 의도는 파악하지 못한 채, 단순히 코딩 테스트 난이도만 높이는 식으로 형식을 답습합니다. 그 결과, 정해진 알고리즘 문제 풀이(LeetCode)는 기계처럼 잘하지만, 정작 실전 데이터 파이프라인의 병목은 찾지 못하는 **&amp;lsquo;시험형 인재&amp;rsquo;**만 양산하고 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[진단 2: 잃어버린 기술력의 시대]&lt;/strong&gt; 여기에 더해 **&amp;lsquo;기계적 형평성&amp;rsquo;**이라는 이름 아래 엔지니어의 차별성을 지워왔습니다. 압도적인 퍼포먼스를 내는 엔지니어와 단순히 자리를 지키는 엔지니어의 보상이 비슷해지면서, 치열하게 기술적 **&amp;lsquo;깊이(Depth)&amp;rsquo;**를 파고드는 것은 손해 보는 장사가 되었습니다. 진짜 실력자들은 떠나고, 남은 자리엔 &amp;lsquo;정치&amp;rsquo;와 &amp;lsquo;스펙&amp;rsquo;으로 무장한 사람들만 남게 된 것입니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[처방: 보상을 넘어선, 사회적 시스템의 대전환]&lt;/strong&gt; 이 문제를 해결하기 위해서는 개별 기업의 보상 정책을 넘어선, 사회적 시스템의 대수술이 필요합니다.&lt;/p&gt;
&lt;p&gt;교육의 혁신 (From Tools to Principles): 현재의 코딩 교육은 &amp;lsquo;도구 사용법&amp;rsquo;을 가르치는 데 급급합니다. 유행하는 프레임워크 이전에 컴퓨터 구조와 메모리 관리 등 **&amp;lsquo;근본 원리&amp;rsquo;**를 가르쳐야 합니다. 화려한 문법보다 **&amp;lsquo;왜(Why)&amp;rsquo;**를 질문하는 엔지니어를 길러내는 것이 교육의 목표가 되어야 합니다.&lt;/p&gt;
&lt;p&gt;사회적 인식의 개선 (Recognition): 엔지니어를 단순히 &amp;lsquo;기능 구현자&amp;rsquo;나 &amp;lsquo;전산실 관리자&amp;rsquo;로 보는 낡은 인식을 버려야 합니다. 데이터 시대의 엔지니어는 건물을 짓는 건축가(Architect)와 같으며, 기업의 자산을 설계하고 지키는 핵심 인력이라는 사회적 합의가 필요합니다.&lt;/p&gt;
&lt;p&gt;합당한 대우와 동기부여 (Compensation): 이러한 인식 개선 위에서, 실력에 따른 파격적인 보상은 자연스러운 귀결이어야 합니다. 최고의 인재들이 의대나 로스쿨이 아닌, &amp;lsquo;데이터 엔지니어링&amp;rsquo;에 인생을 걸고 싶게 만들어야 합니다.&lt;/p&gt;
&lt;p&gt;결국 기업과 사회가 &amp;lsquo;진짜 실력&amp;rsquo;을 알아보고 대우할 때, 비로소 우리 곁에 수많은 &amp;lsquo;Surgical Architect&amp;rsquo;들이 탄생할 것입니다.&lt;/p&gt;
&lt;h4&gt;Conclusion: 기술은 경영의 나침반이다&lt;span class="hx:absolute hx:-mt-20" id="conclusion-기술은-경영의-나침반이다"&gt;&lt;/span&gt;
&lt;a href="#conclusion-%ea%b8%b0%ec%88%a0%ec%9d%80-%ea%b2%bd%ec%98%81%ec%9d%98-%eb%82%98%ec%b9%a8%eb%b0%98%ec%9d%b4%eb%8b%a4" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;데이터 모델링부터 AI 자동화까지, 기술 트렌드는 끊임없이 변화합니다. 하지만 그 모든 기술이 지향해야 할 본질은 변하지 않습니다.&lt;/p&gt;
&lt;p&gt;바로 **&amp;lsquo;기술을 통한 경영의 최적화(Management Optimization)&amp;rsquo;**입니다.&lt;/p&gt;
&lt;p&gt;불확실한 비즈니스 환경 속에서, 가장 정확한 데이터를 가장 합리적인 비용으로 제공하여 경영진의 올바른 의사결정을 돕는 나침반이 되는 것. 이것이 제가 추구하는 Surgical Architecture의 목표이자, 우리 엔지니어링 조직이 나아가야 할 방향입니다.&lt;/p&gt;
&lt;p&gt;도구(Tool)를 탓하지 마십시오. 문제는 그것을 다루는 방식(Method)에 있습니다.&lt;/p&gt;
&lt;img src="../images/bottom_banner.png" width="100%"&gt;</description></item><item><title>[Tez] 2000억 건 로그 처리, 힌트는 필요 없다 : 2GB 컨테이너의 승리</title><link>https://swoo-goh.github.io/blog/data_engineering/tez_optimization/</link><pubDate>Thu, 11 Dec 2025 09:00:00 +0900</pubDate><guid>https://swoo-goh.github.io/blog/data_engineering/tez_optimization/</guid><description>
&lt;img src="../images/cloud_cost_optimization_2.png" width="100%"&gt;
&lt;h4&gt;Executive Summary&lt;span class="hx:absolute hx:-mt-20" id="executive-summary"&gt;&lt;/span&gt;
&lt;a href="#executive-summary" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;span style="font-size: 48px; font-weight: 900; color: #39ff14; background-color: #000000; padding: 5px 10px; border-radius: 5px; letter-spacing: 2px; text-shadow: 0 0 10px #39ff14;"&gt;Just Logic&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;1. 환자 차트 (Patient Chart) : &amp;ldquo;이게 돌아간다고?&amp;rdquo;&lt;span class="hx:absolute hx:-mt-20" id="1-환자-차트-patient-chart--이게-돌아간다고"&gt;&lt;/span&gt;
&lt;a href="#1-%ed%99%98%ec%9e%90-%ec%b0%a8%ed%8a%b8-patient-chart--%ec%9d%b4%ea%b2%8c-%eb%8f%8c%ec%95%84%ea%b0%84%eb%8b%a4%ea%b3%a0" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;대부분의 엔지니어는 이 스펙을 듣는 순간 고개를 저을 것입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;데이터 규모: 2000억 건 (비정형 텍스트 로그 포함)&lt;/li&gt;
&lt;li&gt;복잡도: 100-way Join (Data Mart 생성)&lt;/li&gt;
&lt;li&gt;리소스: 1120 vCore, Total 2TB Memory&lt;/li&gt;
&lt;li&gt;엔진: Hive on Tez&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;일반적인 처방(Diagnosis)이라면 이렇게 말했을 겁니다. &amp;ldquo;컨테이너당 16GB 할당하고, 노드 2배로 늘리세요. 안 그러면 OOM 납니다.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;하지만 저는 정반대의 처방을 내렸습니다. &lt;strong&gt;컨테이너 사이즈 2GB. 힌트(Hint) 없음. 실행 옵션(Execute Option) 없음&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;이것은 무모한 도박이 아니었습니다. 철저한 진단 끝에 내린 **정밀 수술(Surgery)**이었습니다.&lt;/p&gt;
&lt;h4&gt;2. 오진(Misdiagnosis) : 메모리는 죄가 없다&lt;span class="hx:absolute hx:-mt-20" id="2-오진misdiagnosis--메모리는-죄가-없다"&gt;&lt;/span&gt;
&lt;a href="#2-%ec%98%a4%ec%a7%84misdiagnosis--%eb%a9%94%eb%aa%a8%eb%a6%ac%eb%8a%94-%ec%a3%84%ea%b0%80-%ec%97%86%eb%8b%a4" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;처음엔 저도 두려웠습니다. &amp;ldquo;혹시 터지면 어떡하지?&amp;ldquo;라는 마음에 관습적으로 4GB를 할당했었습니다. 하지만 모니터링 툴(Dr. Elephant 등)을 통해 시스템의 비명을 자세히 들어보니, 진짜 병명은 &lt;strong&gt;메모리 부족&lt;/strong&gt;이 아니었습니다.&lt;/p&gt;
&lt;p&gt;범인은 &amp;lsquo;500자 정규식&amp;rsquo; (CPU Bound)
로그를 파싱 하는 Mapper 단계가 병목이었습니다. 원인은 무려 **500자에 달하는 거대한 정규식(Regex)**이었습니다. 이 무거운 연산을 처리하느라 CPU가 비명을 지르고 있는데, 우리는 엉뚱하게 메모리(RAM)만 더 주고 있었던 것입니다. 배 아픈 환자에게 소화제 대신 반창고를 붙이고 있었던 꼴이죠.&lt;/p&gt;
&lt;h4&gt;3. 집도 (The Surgery) : 엔진을 믿지 말고, 데이터를 믿어라&lt;span class="hx:absolute hx:-mt-20" id="3-집도-the-surgery--엔진을-믿지-말고-데이터를-믿어라"&gt;&lt;/span&gt;
&lt;a href="#3-%ec%a7%91%eb%8f%84-the-surgery--%ec%97%94%ec%a7%84%ec%9d%84-%eb%af%bf%ec%a7%80-%eb%a7%90%ea%b3%a0-%eb%8d%b0%ec%9d%b4%ed%84%b0%eb%a5%bc-%eb%af%bf%ec%96%b4%eb%9d%bc" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;저는 Tez 엔진의 자동화 기능에 의존하는 것을 멈췄습니다. 엔진은 마법사가 아닙니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(1) 블랙박스를 열다 : 수동 데이터 분포 분석&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Shuffle Skew는 블랙박스입니다. 화면은 멈춰있고, 로그는 침묵합니다. 저는 이 블랙박스를 열기 위해 원천 데이터를 일일이 SQL로 조회하여 분포를 확인했습니다. 그리고 데이터가 쏠리는(Skew) 키 값들을 찾아내, SQL 레벨에서 직접 분산 로직을 심었습니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(2) Delete 키를 누르다 : Back to Basic&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;가장 중요한 수술은 &lt;strong&gt;더하는 것&lt;/strong&gt;이 아니라 &lt;strong&gt;빼는 것&lt;/strong&gt;이었습니다. 불안감 때문에 덕지덕지 붙였던 메모리 설정, 병렬 처리 옵션들을 전부 지웠습니다(Delete).&lt;/p&gt;
&lt;img src="../images/tez_optimization_1.jpg" width="100%"&gt;
&lt;p&gt;Hortonworks HDP Container Size (Default) = 2GB&lt;/p&gt;
&lt;p&gt;놀랍게도, 순정 상태로 돌아가자 Tez는 본래의 성능을 발휘하기 시작했습니다. 1120 vCore라는 한정된 자원 안에서, 2GB의 가벼운 컨테이너들은 **엄청난 밀도(Density)**로 재사용(Reuse)되며 2000억 건의 데이터를 씹어먹기 시작했습니다.&lt;/p&gt;
&lt;h4&gt;4. 경과 (Recovery) : 120분의 기적&lt;span class="hx:absolute hx:-mt-20" id="4-경과-recovery--120분의-기적"&gt;&lt;/span&gt;
&lt;a href="#4-%ea%b2%bd%ea%b3%bc-recovery--120%eb%b6%84%ec%9d%98-%ea%b8%b0%ec%a0%81" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;수술 결과는 데이터가 증명했습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;수행 시간: 2000억 건 처리 120분 (2시간) 완료.&lt;/li&gt;
&lt;li&gt;안정성: 수술 이후 3개월간 에러율 0%.&lt;/li&gt;
&lt;li&gt;효율: 초기 Stage에서는 리소스를 100% 사용하여 폭발적으로 처리하고, 이후 단계에서는 유려하게 흘려보냄.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;남들이 &amp;ldquo;부족하다&amp;quot;고 했던 2GB는, 사실 시스템이 필요로 하는 &lt;strong&gt;최적의 정량&lt;/strong&gt;이었습니다. 우리가 그동안 낭비했던 수 테라바이트의 메모리는 시스템의 한계가 아니라, 엔지니어의 **공포심(Fear)**이 만들어낸 거품이었습니다.&lt;/p&gt;
&lt;h4&gt;5. 결론 : 최적화의 끝은 &amp;lsquo;순정&amp;rsquo;이다&lt;span class="hx:absolute hx:-mt-20" id="5-결론--최적화의-끝은-순정이다"&gt;&lt;/span&gt;
&lt;a href="#5-%ea%b2%b0%eb%a1%a0--%ec%b5%9c%ec%a0%81%ed%99%94%ec%9d%98-%eb%81%9d%ec%9d%80-%ec%88%9c%ec%a0%95%ec%9d%b4%eb%8b%a4" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;많은 분들이 2000억 건 처리에 대한 &amp;ldquo;특별한 비법&amp;quot;을 묻습니다. 하지만 저는 드릴 말씀이 없습니다.&lt;/p&gt;
&lt;p&gt;저는 그저 데이터를 뜯어보고(Analyze), 쿼리를 다듬고(Refine), 불필요한 설정을 지웠을(Delete) 뿐입니다. 엔지니어링의 정점은 무엇을 더하는 것이 아니라, 불필요한 것을 걷어내는 데 있습니다.&lt;/p&gt;
&lt;img src="../images/cloud_cost_optimization_7.png" width="100%"&gt;</description></item><item><title>클라우드 예산의 32%가 사라지고 있습니다: 인프라가 아닌 '쿼리'를 수술해야 할 때</title><link>https://swoo-goh.github.io/blog/data_engineering/cloud_cost_optimization/</link><pubDate>Tue, 09 Dec 2025 17:00:00 +0900</pubDate><guid>https://swoo-goh.github.io/blog/data_engineering/cloud_cost_optimization/</guid><description>
&lt;h4&gt;&amp;ldquo;시스템은 거짓말을 하지 않습니다. 다만 청구서로 비명을 지를 뿐입니다.&amp;rdquo;&lt;span class="hx:absolute hx:-mt-20" id="시스템은-거짓말을-하지-않습니다-다만-청구서로-비명을-지를-뿐입니다"&gt;&lt;/span&gt;
&lt;a href="#%ec%8b%9c%ec%8a%a4%ed%85%9c%ec%9d%80-%ea%b1%b0%ec%a7%93%eb%a7%90%ec%9d%84-%ed%95%98%ec%a7%80-%ec%95%8a%ec%8a%b5%eb%8b%88%eb%8b%a4-%eb%8b%a4%eb%a7%8c-%ec%b2%ad%ea%b5%ac%ec%84%9c%eb%a1%9c-%eb%b9%84%eb%aa%85%ec%9d%84-%ec%a7%80%eb%a5%bc-%eb%bf%90%ec%9e%85%eb%8b%88%eb%8b%a4" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;img src="../images/cloud_cost_optimization_2.png" width="100%"&gt;
&lt;p&gt;클라우드 비용 절감(FinOps)을 논할 때, 대부분의 관리자는 이렇게 외칩니다. &amp;ldquo;주말에 개발 서버 껐어? 스팟 인스턴스(Spot Instance) 적용했어?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;물론 중요합니다. 하지만 이것은 &lt;strong&gt;수도꼭지 잠그기&lt;/strong&gt;에 불과합니다. 진짜 문제는 수도꼭지가 아니라, 파이프라인 안에서 줄줄 새고 있는 물(Resource) 그 자체에 있습니다.&lt;/p&gt;
&lt;p&gt;오늘은 인프라 엔지니어가 아닌, 데이터 엔지니어/아키텍트의 관점에서 비용 낭비의 진짜 원인을 진단해 봅니다.&lt;/p&gt;
&lt;h4&gt;1. 팩트 체크 : 낭비되는 돈의 실체&lt;span class="hx:absolute hx:-mt-20" id="1-팩트-체크--낭비되는-돈의-실체"&gt;&lt;/span&gt;
&lt;a href="#1-%ed%8c%a9%ed%8a%b8-%ec%b2%b4%ed%81%ac--%eb%82%ad%eb%b9%84%eb%90%98%eb%8a%94-%eb%8f%88%ec%9d%98-%ec%8b%a4%ec%b2%b4" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;img src="../images/cloud_cost_optimization_1.png" width="100%"&gt;
&lt;p&gt;Flexera의 2024 State of the Cloud Report에 따르면, 기업들은 클라우드 예산의 최소 **32%**가 낭비되고 있다고 스스로 인정했습니다. 재미있는 사실은, 실제 낭비 규모는 이보다 훨씬 클 것이라는 점입니다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Flexera&lt;/strong&gt;, &lt;a href="https://www.flexera.com/blog/finops/cloud-computing-trends-flexera-2024-state-of-the-cloud-report/"target="_blank" rel="noopener"&gt;2024 State of the Cloud Report&lt;/a&gt; : 기업 클라우드 지출의 최소 32%가 낭비 통계&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;여기서 주목해야 할 점은, 이 수치가 모던 데이터 플랫폼의 발전에도 불구하고 여전히 높다는 사실입니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;벤더사의 노력 (Idle 최소화): Snowflake, Databricks, BigQuery 같은 최신 플랫폼들은 이미 Auto-suspend나 Serverless 기술을 통해 작업이 끝나면 즉시 자원을 회수합니다. 즉, &lt;strong&gt;안 쓸 때 불을 끄는 기술&lt;/strong&gt;은 이미 완성 단계입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;여전한 낭비 (Inefficient Compute): 그런데도 왜 32%나 낭비될까요? 서버가 꺼져 있을 때(Idle)가 아니라, 서버가 켜져서 돌아가는 그 순간에 낭비가 발생하기 때문입니다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;마치 &amp;lsquo;스탑 앤 고(Stop &amp;amp; Go)&amp;rsquo; 기능이 있는 최신 스포츠카를 타고, 꽉 막힌 도심에서 시속 10km로 가면서 엑셀을 풀로 밟고 있는 것과 같습니다. 엔진은 신호 대기 중에 자동으로 꺼지겠지만(Idle 최적화), 달리는 동안 연비는 최악(Inefficient Compute)인 상황.&lt;/p&gt;
&lt;p&gt;이것이 바로 플랫폼 벤더가 해결해 줄 수 없는, 오직 엔지니어의 몫으로 남은 낭비의 영역입니다.&lt;/p&gt;
&lt;h4&gt;2. 진단 : 서버를 안 끈 것이 아니라, 자원을 &amp;lsquo;과식&amp;rsquo;한 것이 문제다&lt;span class="hx:absolute hx:-mt-20" id="2-진단--서버를-안-끈-것이-아니라-자원을-과식한-것이-문제다"&gt;&lt;/span&gt;
&lt;a href="#2-%ec%a7%84%eb%8b%a8--%ec%84%9c%eb%b2%84%eb%a5%bc-%ec%95%88-%eb%81%88-%ea%b2%83%ec%9d%b4-%ec%95%84%eb%8b%88%eb%9d%bc-%ec%9e%90%ec%9b%90%ec%9d%84-%ea%b3%bc%ec%8b%9d%ed%95%9c-%ea%b2%83%ec%9d%b4-%eb%ac%b8%ec%a0%9c%eb%8b%a4" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;우리는 인프라의 낭비와 애플리케이션의 낭비를 명확히 구분해야 합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;인프라의 낭비 (Idle): 퇴근할 때 불 안 끄고 나가는 것.&lt;/li&gt;
&lt;li&gt;애플리케이션의 낭비 (Over-provisioning): 혼자 밥 먹으러 가서 4인분을 시키고 3인분을 버리는 것.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;빅데이터 성능 최적화 기업 Pepperdata의 리포트에 따르면, 클라우드 데이터 워크로드의 **약 40%**가 과도한 자원 할당(Over-provisioning)으로 인해 낭비되고 있다고 합니다. 심한 경우 할당된 자원의 **60%**가 실제로는 사용되지 않고 증발합니다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;AWS Partner Network&lt;/strong&gt;, &lt;a href="https://aws.amazon.com/blogs/apn/how-a-global-technology-firm-realized-up-to-25-percent-cost-savings-on-amazon-emr-with-pepperdata/"target="_blank" rel="noopener"&gt;Cost Savings on Amazon EMR with Pepperdata&lt;/a&gt; : 개발자들의 Over-provisioning 관행과 비용 절감 사례&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;왜 이런 일이 벌어질까요? 범인은 바로 엔지니어의 **공포(Fear)**입니다.&lt;/p&gt;
&lt;h4&gt;3. 공포가 만든 청구서 : &amp;ldquo;일단 크게 잡고 보자&amp;rdquo;&lt;span class="hx:absolute hx:-mt-20" id="3-공포가-만든-청구서--일단-크게-잡고-보자"&gt;&lt;/span&gt;
&lt;a href="#3-%ea%b3%b5%ed%8f%ac%ea%b0%80-%eb%a7%8c%eb%93%a0-%ec%b2%ad%ea%b5%ac%ec%84%9c--%ec%9d%bc%eb%8b%a8-%ed%81%ac%ea%b2%8c-%ec%9e%a1%ea%b3%a0-%eb%b3%b4%ec%9e%90" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;img src="../images/cloud_cost_optimization_3.png" width="100%"&gt;
&lt;p&gt;데이터 엔지니어들에게 OOM(Out Of Memory) 에러는 공포 그 자체입니다. 새벽 3시에 배치가 죽어서 알람이 울리는 것을 막기 위해, 엔지니어들은 본능적으로 **안전 마진(Safety Margin)**을 설정합니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;실제 필요량: 8GB 메모리.&lt;/li&gt;
&lt;li&gt;엔지니어의 심리: &amp;ldquo;혹시 모르니까 20GB 주자. 아니, 지난번에 터졌으니까 32GB 주자.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;결과: YARN/Kubernetes 상에서 컨테이너는 32GB를 점유하지만, 실제 JVM Heap은 5GB도 쓰지 않습니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;나머지 27GB는? 아무 일도 하지 않지만, 비용은 100% 청구됩니다. 이것이 바로 인프라 팀장이 아무리 서버를 꺼도 비용이 줄지 않는 진짜 이유입니다.&lt;/p&gt;
&lt;h4&gt;4. 설상가상 : 텅 빈 경기장 (The Empty Stadium)&lt;span class="hx:absolute hx:-mt-20" id="4-설상가상--텅-빈-경기장-the-empty-stadium"&gt;&lt;/span&gt;
&lt;a href="#4-%ec%84%a4%ec%83%81%ea%b0%80%ec%83%81--%ed%85%85-%eb%b9%88-%ea%b2%bd%ea%b8%b0%ec%9e%a5-the-empty-stadium" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;개별 엔지니어의 공포(Job Over-provisioning)가 &lt;strong&gt;내부의 낭비&lt;/strong&gt;라면, 잘못된 용량 산정(Capacity Planning)은 &lt;strong&gt;외부의 낭비&lt;/strong&gt;를 만듭니다.&lt;/p&gt;
&lt;p&gt;많은 아키텍트들이 **1년 중 단 3일뿐인 피크 타임(Peak)**을 기준으로 클러스터 전체 사이즈를 고정하는 실수를 범합니다. &amp;ldquo;피크 타임에 대기열(Queue)이 생기면 안 된다&amp;quot;는 강박 때문입니다.&lt;/p&gt;
&lt;p&gt;하지만 스케줄러(Scheduler)는 폼으로 있는 것이 아닙니다. YARN이나 Kubernetes의 스케줄러는 자원이 부족할 때 Job을 잠시 대기(Pending)시키고, 순차적으로 처리하라고 만든 것입니다.&lt;/p&gt;
&lt;p&gt;피크 타임의 잠깐의 대기(Latency)를 허용하지 않겠다고 365일 내내 월드컵 경기장(Max Peak Size)을 유지하는 것. 그 안에서 엔지니어들은 10명도 안 되는 조기축구회(Small Jobs)를 하며 4인분 밥을 시키고 있는 것.&lt;/p&gt;
&lt;p&gt;이것이 바로 이중(Double)으로 새는 클라우드 비용의 전말입니다.&lt;/p&gt;
&lt;h4&gt;5. 처방 : 인프라를 끄지 말고, 쿼리를 수술하라&lt;span class="hx:absolute hx:-mt-20" id="5-처방--인프라를-끄지-말고-쿼리를-수술하라"&gt;&lt;/span&gt;
&lt;a href="#5-%ec%b2%98%eb%b0%a9--%ec%9d%b8%ed%94%84%eb%9d%bc%eb%a5%bc-%eb%81%84%ec%a7%80-%eb%a7%90%ea%b3%a0-%ec%bf%bc%eb%a6%ac%eb%a5%bc-%ec%88%98%ec%88%a0%ed%95%98%eb%9d%bc" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;결국 근본적인 해결책은 **Surgical Engineering(정밀한 엔지니어링)**에 있습니다. 그리고 그 수술의 결과는 단순히 메모리 몇 기가를 아끼는 것이 아니라, 필요한 총 서버 대수를 줄이는 것으로 나타납니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Logic Optimization: 무식하게 데이터를 다 올리는 대신, 필요한 데이터만 필터링하고 있는가?&lt;/li&gt;
&lt;li&gt;High Density Strategy: 컨테이너 사이즈를 줄여 **노드 당 집적도(Density)**를 높이고 있는가?&lt;/li&gt;
&lt;li&gt;Engine Tuning: Tez나 Spark의 메모리 모델을 이해하고, 불필요한 버퍼를 걷어냈는가?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;ldquo;메모리 최적화는 곧 노드 절감입니다.&amp;rdquo; 예를 들어, 64GB 메모리를 가진 노드에서 8GB짜리 컨테이너를 쓴다면 고작 8개밖에 실행하지 못합니다. 하지만 이를 튜닝하여 2GB로 줄인다면? 같은 노드에서 32개의 태스크를 동시에 처리할 수 있습니다.&lt;/p&gt;
&lt;p&gt;즉, 동일한 성능을 내기 위해 예전에는 100대의 서버가 필요했다면, 최적화 후에는 25대만 있어도 충분하다는 계산이 나옵니다. 저는 이 방식으로 최근 2000억 건의 비정형 로그 데이터를 처리하는 프로젝트에서, 남들이 &amp;ldquo;최소 16GB는 줘야 한다&amp;quot;고 했던 컨테이너 사이즈를 2GB까지 줄였습니다. 덕분에 한정된 vCore 안에서도 폭발적인 병렬 처리가 가능했습니다.&lt;/p&gt;
&lt;p&gt;단순히 메모리 공간을 비우는 것이 아닙니다. &amp;lsquo;뚱뚱한 컨테이너&amp;rsquo; 때문에 낭비되던 물리 서버들을 반납하고, &lt;strong&gt;날렵한 아키텍처&lt;/strong&gt;로 클러스터 전체의 부피를 줄이는 것. 이것이 진짜 수술입니다.&lt;/p&gt;
&lt;p&gt;(다음 글 예고: [Tez] 2000억 건 로그 처리, 힌트는 필요 없다 - 2GB 컨테이너의 승리)&lt;/p&gt;
&lt;div class="hx:overflow-x-auto hx:mt-6 hx:flex hx:rounded-lg hx:border hx:py-2 hx:ltr:pr-4 hx:rtl:pl-4 hx:contrast-more:border-current hx:contrast-more:dark:border-current hx:border-amber-200 hx:bg-amber-100 hx:text-amber-900 hx:dark:border-amber-200/30 hx:dark:bg-amber-900/30 hx:dark:text-amber-200"&gt;
&lt;div class="hx:ltr:pl-3 hx:ltr:pr-2 hx:rtl:pr-3 hx:rtl:pl-2"&gt;&lt;svg height=1.2em class="hx:inline-block hx:align-middle" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"&gt;&lt;path stroke-linecap="round" stroke-linejoin="round" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z"/&gt;&lt;/svg&gt;&lt;/div&gt;
&lt;div class="hx:w-full hx:min-w-0 hx:leading-7"&gt;
&lt;div class="hx:mt-6 hx:leading-7 hx:first:mt-0"&gt;Warning : 수술 면허 없는 집도 금지&lt;br&gt;
본문의 최적화 기법(Resource Cut)은 데이터 모델, 쿼리 효율 등이 완벽한 상태를 전제로 합니다.&lt;br&gt;
환부(Bad Query)를 도려내지 않은 채 생명 유지 장치(Resource)만 끄게 되면, 여러분의 클러스터는 비용 절감이 아니라 즉사(Immediate Death) 할 수 있습니다.&lt;br&gt;
반드시 &amp;lsquo;진단&amp;rsquo;과 &amp;lsquo;최적화&amp;rsquo;가 선행된 후에 적용하십시오.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4&gt;5. 결론&lt;span class="hx:absolute hx:-mt-20" id="5-결론"&gt;&lt;/span&gt;
&lt;a href="#5-%ea%b2%b0%eb%a1%a0" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;비용 절감은 재무팀의 엑셀 시트에서 이루어지는 것이 아닙니다. 엔지니어의 IDE와 쿼리 창에서 이루어집니다.&lt;/p&gt;
&lt;p&gt;지금 당신의 클러스터는 일을 하고 있습니까, 아니면 그저 자원을 점유하고 있습니까? 이제 &lt;strong&gt;안전한 낭비&lt;/strong&gt;를 멈추고, &lt;strong&gt;정밀한 수술&lt;/strong&gt;을 시작할 때입니다.&lt;/p&gt;
&lt;img src="../images/cloud_cost_optimization_7.png" width="100%"&gt;</description></item></channel></rss>