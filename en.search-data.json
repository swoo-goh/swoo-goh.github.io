{"/about/":{"data":{"":"","1-기술로-경영을-최적화-하라#1. 기술로 경영을 최적화 하라":"“비즈니스에 어떤 효과가 발생하는가?”\nBI(Business Intelligence)는 단순히 의사결정을 위한 지표와 집계 데이터만 생산하는 시스템이 아닙니다.\n기술적으로 Bill Inmon 방법론에서는 데이터의 신뢰성을, Ralph Kimball의 방법론에서는 데이터의 확장성을 중시합니다. 하지만 이들이 공통적으로 지향하는 점은 하나입니다. 바로 기술에 의한 경영의 최적화입니다.\n이 목표를 달성하기 위해서는 기술적인 논리적(Logical) 구현과 물리적(Physical) 구현이 필수적으로 선행되어야 합니다.","2-논리적-구현-1단계---객체관계모델링-the-foundation#2. 논리적 구현 1단계 - 객체관계모델링 (The Foundation)":"객체관계 모델링은 추상화를 통해 데이터를 유연하게 확장할 수 있도록 설계하는 기술입니다.\n이 설계 기법과 원칙에는 데이터 품질 유지라는 목적이 존재하며, 이는 데이터의 신뢰성과 확장성을 보장하게 됩니다. 즉, 객체관계 모델링은 데이터 활용을 위한 견고한 기둥을 구축하는 과정입니다.\n데이터 엔지니어링에는 Garbage In, Garbage Out이라는 말이 있습니다. 원천 데이터가 쓰레기이면, 아무리 좋은 분석 모델을 돌려도 결과는 쓰레기라는 의미입니다. 오염된 데이터의 유입을 원천 봉쇄하는 첫 단계, 그것이 바로 객체관계 모델링입니다.","3-논리적-구현-2단계---다차원모델링-the-connection#3. 논리적 구현 2단계 - 다차원모델링 (The Connection)":"잘 설계된 다차원 모델에는 전사의 많은 지성이 담겨 있습니다.\n영업, 재무, 회계 등의 부서에서는 각자 다른 관점으로 데이터를 바라보게 됩니다. 다차원 모델은 이 서로 다른 관점들을 연결하는 연결고리를 만들어 줍니다.\n이는 각 부서가 갇혀 있던 지성의 사일로(Silo) 영역을 벗어나, 전사의 집단 지성을 통해 비즈니스 지능을 최대로 끌어올리게 합니다. 그리하여 우리는 최종 목표인 경영의 최적화를 달성할 수 있게 됩니다.","4-물리적-구현---아키텍처-및-성능-최적화-the-performance--cost#4. 물리적 구현 - 아키텍처 및 성능 최적화 (The Performance \u0026amp; Cost)":"물리적 구현이 단지 고성능의 컴퓨팅 파워를 가진 인프라를 구축하라는 의미는 아닙니다. 논리적으로 구현한 전략을 한정된 비용 내에서 구현 가능하도록 하는 것이 물리적 구현의 진짜 목적입니다.\n물리적 구현을 위한 **TCO(총소유비용)**와 Engineering 비용이 **ROI(투자 대비 수익)**를 넘어서면, 심해 탐사는 가치 없는 일로 치부될 테니까요.\n데이터 분석을 위한 환경은 심해의 혹독함과 유사합니다. 물리적으로 최적화되어 있지 않다면, 시스템은 엄청난 데이터의 양에 압사되어 **오랜 시간(Timeout)**이 걸리거나 실패(OOM) 할 것입니다.\n돈을 쏟아부어 해결하는 것에는 한계가 있습니다. 물리적 최적화가 되지 않았다면 컴퓨팅 파워를 2배 올려도 퍼포먼스는 1.2배만이 개선되기 때문입니다. 실제로 2024년 데이터 플랫폼에서 낭비되는 Cloud 비용이 최소 30% 이상이며, 이는 대부분 물리적 최적화 부재에서 기인합니다.\nOn-Premise 시절에는 비용 산정의 모호함에 가려져 보이지 않았던 비효율이, 이제는 Cloud 청구서라는 성적표로 명확히 드러나고 있습니다. 그렇기에 아키텍처 및 성능 최적화는 선택이 아닌 필수입니다.","5-보물-발견-the-value#5. 보물 발견 (The Value)":"논리적, 물리적 기반을 갖추게 되었다면 분석가들은 이제 보물을 찾는 일에만 집중할 수 있습니다.\n길을 헤매고, 고장 난 잠수정을 보수하는 일에 노력을 낭비하는 비용이 사라졌음을 의미합니다. 이것이 모든 소프트웨어 공학 방법론이 지향하는 관심사 집중에 의한 인적 비용 최적화와 목표 달성의 핵심입니다.\n또한 분석가, 현업 부서간의 지성의 사일로를 넘어 집단지성 효율을 극대화함으로써 기술을 통한 경영의 최적화를 완성하게 됩니다.\n분석가는 발견하고, 아키텍트는 도달하게 합니다.","contact#Contact":"email : swoo.goh@gmail.com","심해의-어둠-속에서-보물insight로-향하는-길을-엽니다#심해의 어둠 속에서, 보물(Insight)로 향하는 길을 엽니다":"데이터의 세계는 빛 한 점 들어오지 않는 **심해(Deep Sea)**와 같습니다. 그곳엔 엄청난 가치의 보물이 숨겨져 있지만, 준비 없이 뛰어든 자에게는 무자비한 수압과 암흑만이 기다릴 뿐입니다.\n분석가(Analyst)가 보물을 찾는 탐험가라면, 아키텍트(Architect)는 그들을 안전하게 심연으로 데려가는 잠수정을 짓는 사람입니다.\n논리적 구현(Logical) : 어둠을 뚫고 대상을 비추는 서치라이트가 되어, 길을 잃지 않게 합니다.\n물리적 구현(Physical) : 수천 억 건의 데이터 수압을 견뎌내며, 시스템이 파괴되지 않도록 지켜냅니다.\n견고한 잠수정이 없다면 탐사는 조난으로 끝납니다. 분석가들이 기술적 한계에 부딪혀 허우적대지 않고, 오직 보물(Insight)의 발견에만 집중할 수 있도록. 가장 안전하고 강력한 탐사선을 구축합니다."},"title":"ABOUT"},"/blog/":{"data":{"":""},"title":"_index"},"/blog/data_engineering/cloud_cost_optimization/":{"data":{"":"","1-팩트-체크--낭비되는-돈의-실체#1. 팩트 체크 : 낭비되는 돈의 실체":"Flexera의 2024 State of the Cloud Report에 따르면, 기업들은 클라우드 예산의 최소 **32%**가 낭비되고 있다고 스스로 인정했습니다. 재미있는 사실은, 실제 낭비 규모는 이보다 훨씬 클 것이라는 점입니다.\nFlexera, 2024 State of the Cloud Report : 기업 클라우드 지출의 최소 32%가 낭비 통계\n여기서 주목해야 할 점은, 이 수치가 모던 데이터 플랫폼의 발전에도 불구하고 여전히 높다는 사실입니다.\n벤더사의 노력 (Idle 최소화): Snowflake, Databricks, BigQuery 같은 최신 플랫폼들은 이미 Auto-suspend나 Serverless 기술을 통해 작업이 끝나면 즉시 자원을 회수합니다. 즉, 안 쓸 때 불을 끄는 기술은 이미 완성 단계입니다.\n여전한 낭비 (Inefficient Compute): 그런데도 왜 32%나 낭비될까요? 서버가 꺼져 있을 때(Idle)가 아니라, 서버가 켜져서 돌아가는 그 순간에 낭비가 발생하기 때문입니다.\n마치 ‘스탑 앤 고(Stop \u0026 Go)’ 기능이 있는 최신 스포츠카를 타고, 꽉 막힌 도심에서 시속 10km로 가면서 엑셀을 풀로 밟고 있는 것과 같습니다. 엔진은 신호 대기 중에 자동으로 꺼지겠지만(Idle 최적화), 달리는 동안 연비는 최악(Inefficient Compute)인 상황.\n이것이 바로 플랫폼 벤더가 해결해 줄 수 없는, 오직 엔지니어의 몫으로 남은 낭비의 영역입니다.","2-진단--서버를-안-끈-것이-아니라-자원을-과식한-것이-문제다#2. 진단 : 서버를 안 끈 것이 아니라, 자원을 \u0026lsquo;과식\u0026rsquo;한 것이 문제다":"우리는 인프라의 낭비와 애플리케이션의 낭비를 명확히 구분해야 합니다.\n인프라의 낭비 (Idle): 퇴근할 때 불 안 끄고 나가는 것. 애플리케이션의 낭비 (Over-provisioning): 혼자 밥 먹으러 가서 4인분을 시키고 3인분을 버리는 것. 빅데이터 성능 최적화 기업 Pepperdata의 리포트에 따르면, 클라우드 데이터 워크로드의 **약 40%**가 과도한 자원 할당(Over-provisioning)으로 인해 낭비되고 있다고 합니다. 심한 경우 할당된 자원의 **60%**가 실제로는 사용되지 않고 증발합니다.\nAWS Partner Network, Cost Savings on Amazon EMR with Pepperdata : 개발자들의 Over-provisioning 관행과 비용 절감 사례\n왜 이런 일이 벌어질까요? 범인은 바로 엔지니어의 **공포(Fear)**입니다.","3-공포가-만든-청구서--일단-크게-잡고-보자#3. 공포가 만든 청구서 : \u0026ldquo;일단 크게 잡고 보자\u0026rdquo;":"데이터 엔지니어들에게 OOM(Out Of Memory) 에러는 공포 그 자체입니다. 새벽 3시에 배치가 죽어서 알람이 울리는 것을 막기 위해, 엔지니어들은 본능적으로 **안전 마진(Safety Margin)**을 설정합니다.\n실제 필요량: 8GB 메모리. 엔지니어의 심리: “혹시 모르니까 20GB 주자. 아니, 지난번에 터졌으니까 32GB 주자.” 결과: YARN/Kubernetes 상에서 컨테이너는 32GB를 점유하지만, 실제 JVM Heap은 5GB도 쓰지 않습니다. 나머지 27GB는? 아무 일도 하지 않지만, 비용은 100% 청구됩니다. 이것이 바로 인프라 팀장이 아무리 서버를 꺼도 비용이 줄지 않는 진짜 이유입니다.","4-설상가상--텅-빈-경기장-the-empty-stadium#4. 설상가상 : 텅 빈 경기장 (The Empty Stadium)":"개별 엔지니어의 공포(Job Over-provisioning)가 내부의 낭비라면, 잘못된 용량 산정(Capacity Planning)은 외부의 낭비를 만듭니다.\n많은 아키텍트들이 **1년 중 단 3일뿐인 피크 타임(Peak)**을 기준으로 클러스터 전체 사이즈를 고정하는 실수를 범합니다. “피크 타임에 대기열(Queue)이 생기면 안 된다\"는 강박 때문입니다.\n하지만 스케줄러(Scheduler)는 폼으로 있는 것이 아닙니다. YARN이나 Kubernetes의 스케줄러는 자원이 부족할 때 Job을 잠시 대기(Pending)시키고, 순차적으로 처리하라고 만든 것입니다.\n피크 타임의 잠깐의 대기(Latency)를 허용하지 않겠다고 365일 내내 월드컵 경기장(Max Peak Size)을 유지하는 것. 그 안에서 엔지니어들은 10명도 안 되는 조기축구회(Small Jobs)를 하며 4인분 밥을 시키고 있는 것.\n이것이 바로 이중(Double)으로 새는 클라우드 비용의 전말입니다.","5-결론#5. 결론":"비용 절감은 재무팀의 엑셀 시트에서 이루어지는 것이 아닙니다. 엔지니어의 IDE와 쿼리 창에서 이루어집니다.\n지금 당신의 클러스터는 일을 하고 있습니까, 아니면 그저 자원을 점유하고 있습니까? 이제 안전한 낭비를 멈추고, 정밀한 수술을 시작할 때입니다.","5-처방--인프라를-끄지-말고-쿼리를-수술하라#5. 처방 : 인프라를 끄지 말고, 쿼리를 수술하라":"결국 근본적인 해결책은 **Surgical Engineering(정밀한 엔지니어링)**에 있습니다. 그리고 그 수술의 결과는 단순히 메모리 몇 기가를 아끼는 것이 아니라, 필요한 총 서버 대수를 줄이는 것으로 나타납니다.\nLogic Optimization: 무식하게 데이터를 다 올리는 대신, 필요한 데이터만 필터링하고 있는가? High Density Strategy: 컨테이너 사이즈를 줄여 **노드 당 집적도(Density)**를 높이고 있는가? Engine Tuning: Tez나 Spark의 메모리 모델을 이해하고, 불필요한 버퍼를 걷어냈는가? “메모리 최적화는 곧 노드 절감입니다.” 예를 들어, 64GB 메모리를 가진 노드에서 8GB짜리 컨테이너를 쓴다면 고작 8개밖에 실행하지 못합니다. 하지만 이를 튜닝하여 2GB로 줄인다면? 같은 노드에서 32개의 태스크를 동시에 처리할 수 있습니다.\n즉, 동일한 성능을 내기 위해 예전에는 100대의 서버가 필요했다면, 최적화 후에는 25대만 있어도 충분하다는 계산이 나옵니다. 저는 이 방식으로 최근 2000억 건의 비정형 로그 데이터를 처리하는 프로젝트에서, 남들이 “최소 16GB는 줘야 한다\"고 했던 컨테이너 사이즈를 2GB까지 줄였습니다. 덕분에 한정된 vCore 안에서도 폭발적인 병렬 처리가 가능했습니다.\n단순히 메모리 공간을 비우는 것이 아닙니다. ‘뚱뚱한 컨테이너’ 때문에 낭비되던 물리 서버들을 반납하고, 날렵한 아키텍처로 클러스터 전체의 부피를 줄이는 것. 이것이 진짜 수술입니다.\n(다음 글 예고: [Tez] 2000억 건 로그 처리, 힌트는 필요 없다 - 2GB 컨테이너의 승리)\nWarning : 수술 면허 없는 집도 금지\n본문의 최적화 기법(Resource Cut)은 데이터 모델, 쿼리 효율 등이 완벽한 상태를 전제로 합니다.\n환부(Bad Query)를 도려내지 않은 채 생명 유지 장치(Resource)만 끄게 되면, 여러분의 클러스터는 비용 절감이 아니라 즉사(Immediate Death) 할 수 있습니다.\n반드시 ‘진단’과 ‘최적화’가 선행된 후에 적용하십시오.","시스템은-거짓말을-하지-않습니다-다만-청구서로-비명을-지를-뿐입니다#\u0026ldquo;시스템은 거짓말을 하지 않습니다. 다만 청구서로 비명을 지를 뿐입니다.\u0026rdquo;":"클라우드 비용 절감(FinOps)을 논할 때, 대부분의 관리자는 이렇게 외칩니다. “주말에 개발 서버 껐어? 스팟 인스턴스(Spot Instance) 적용했어?”\n물론 중요합니다. 하지만 이것은 수도꼭지 잠그기에 불과합니다. 진짜 문제는 수도꼭지가 아니라, 파이프라인 안에서 줄줄 새고 있는 물(Resource) 그 자체에 있습니다.\n오늘은 인프라 엔지니어가 아닌, 데이터 엔지니어/아키텍트의 관점에서 비용 낭비의 진짜 원인을 진단해 봅니다."},"title":"클라우드 예산의 32%가 사라지고 있습니다: 인프라가 아닌 '쿼리'를 수술해야 할 때"},"/blog/data_engineering/cloud_cost_optimization2/":{"data":{"":"","1-intro-약속된-낙원은-없었다-the-cloud-paradox#1. Intro: \u0026lsquo;약속된 낙원\u0026rsquo;은 없었다 (The Cloud Paradox)":"수년 전, 우리가 안정적인 온프레미스(On-Premise) 환경을 뒤로하고 대대적인 ‘클라우드 마이그레이션’을 감행했던 이유는 명확했습니다.\n첫째는 **인프라 비용의 획기적 절감(Cost Efficiency)**이었고, 둘째는 하드웨어 관리에서 해방되어 **전문적인 서비스 관리(Managed Service)**를 받기 위함이었습니다.\n하지만 2025년 현재, 우리가 받아든 성적표는 어떻습니까? **‘비용 절감’**은커녕 예측 불가능한 변동비 폭탄을 맞고 있으며, **‘관리의 편의성’**은 복잡해진 아키텍처와 청구서 분석이라는 새로운 관리 비용으로 치환되었습니다. 우리는 ‘하드웨어’라는 짐을 내려놓은 대신, ‘비용’이라는 더 무거운 짐을 지게 되었습니다.\n“그렇다면 답은 다시 온프레미스로의 회귀일까요?”\n결단코 아닙니다. 2025년의 비즈니스 환경에서 클라우드를 포기하는 것은, 무기를 버리고 전장에 나가는 것과 같습니다. 우리가 비싼 수업료를 내면서도 클라우드에 머물러야 하는 이유는 여전히 유효합니다.\n글로벌 확장과 민첩성 (Globalization \u0026 Speed): 한국에서 버튼 하나로 전 세계 리전(Region)에 서비스를 배포하고, 새로운 AI 모델의 PoC/BMT를 즉시 수행할 수 있는 속도는 물리 서버가 따라올 수 없습니다.\n탄력적 대응 (Scalability): 트래픽이 폭주하는 ‘이벤트 데이’에만 서버를 늘렸다가 줄이는 유연성은, 유휴 자원(Idle Resource) 낭비를 막는 유일한 길입니다.\n엔터프라이즈급 보안 (Security): 올해 발생한 연쇄적인 보안 사고들을 보십시오. 천문학적인 예산과 최고의 인재를 보유한 ‘빅테크(Big Tech)’ 기업들의 보안망조차 속수무책으로 뚫렸습니다. 이는 개별 기업이 자체적으로 구축한 온프레미스 방어막으로는 고도화된 위협을 막아내는 데 한계가 있음을 시사합니다. 오히려 클라우드 벤더의 거대한 ‘보안 우산(Security Umbrella)’ 아래에서 글로벌 표준을 방어하는 것이 가장 현실적인 생존 전략입니다.\n문제는 ‘클라우드’라는 도구 자체가 아닙니다. 문제는 그것을 사용하는 우리의 ‘방만함’입니다.\n편리한 관리형 서비스 뒤에는 **‘벤더 종속(Lock-in)’**이라는 족쇄가 기다리고 있고, 무심코 설계한 아키텍처 사이로 **‘데이터 전송료(Egress Fee)’**와 **‘API 호출 비용’**이 새어 나갑니다.\n가장 혁신적인 도구를 가장 비효율적인 방식(Legacy)으로 사용하고 있기에 비용 폭탄을 맞는 것입니다. 이제는 인정해야 합니다. 단순히 클라우드로 옮기는 것만으로는 혁신이 완성되지 않습니다. 무분별한 확장(Expansion)을 멈추고, **정밀한 수술(Surgery)**을 통해 시스템의 체질을 바꿔야 할 때입니다.","conclusion-기술은-경영의-나침반이다#Conclusion: 기술은 경영의 나침반이다":"데이터 모델링부터 AI 자동화까지, 기술 트렌드는 끊임없이 변화합니다. 하지만 그 모든 기술이 지향해야 할 본질은 변하지 않습니다.\n바로 **‘기술을 통한 경영의 최적화(Management Optimization)’**입니다.\n불확실한 비즈니스 환경 속에서, 가장 정확한 데이터를 가장 합리적인 비용으로 제공하여 경영진의 올바른 의사결정을 돕는 나침반이 되는 것. 이것이 제가 추구하는 Surgical Architecture의 목표이자, 우리 엔지니어링 조직이 나아가야 할 방향입니다.\n도구(Tool)를 탓하지 마십시오. 문제는 그것을 다루는 방식(Method)에 있습니다.","surgery-1-스토리지의-혁신--적재store에서-관리manage로#Surgery 1. 스토리지의 혁신 : \u0026ldquo;적재(Store)에서 관리(Manage)로\u0026rdquo;":"[증상: The Data Swamp] 많은 기업이 데이터 레이크(Data Lake)를 구축했지만, 실상은 데이터가 중복되어 쌓여만 가는 ‘데이터 늪’에 가깝습니다. v1, v2, final, real_final… 수정과 삭제가 어려운 기존 파일 시스템의 한계로 인해, 불필요한 스토리지 비용이 눈덩이처럼 불어나고 있습니다.\n[처방: Modern Table Format 도입] Apache Iceberg, Hudi, Delta Lake와 같은 현대적인 테이블 포맷은 스토리지 관리의 패러다임을 바꿉니다.\n단일 소스(Single Source): 데이터를 물리적으로 복제하지 않고, 논리적 스냅샷(Snapshot)으로 버전을 관리하여 스토리지 낭비를 최소화합니다.\nTime Travel \u0026 ACID: 과거 시점 조회와 완벽한 트랜잭션 지원으로, 데이터 정합성을 맞추기 위해 파티션을 통째로 엎는 비효율을 제거합니다.\n탈(脫) 벤더: 특정 클라우드 벤더의 포맷이 아닌 오픈 포맷을 사용함으로써, 향후 발생할 수 있는 데이터 인질극(Lock-in)에서 자유로워집니다.","surgery-2-컴퓨팅의-최적화--목적에-부합하는-엔진fit-for-purpose#Surgery 2. 컴퓨팅의 최적화 : \u0026ldquo;목적에 부합하는 엔진(Fit for Purpose)\u0026rdquo;":"[증상: One Size Fits All] 100GB 배치도 Spark, 10GB 조회도 Spark, 1TB ETL도 Spark. 특정 엔진 하나로 모든 데이터 처리를 수행하려는 ‘만능주의’가 만연해 있습니다.\n[처방: Layered Engine Architecture] 우리는 먼저 인정해야 합니다. 시장에 나와 있는 Spark, Tez, Trino 등은 모두 각자의 영역에서 최고의 성능을 내도록 설계된 **‘엔지니어링의 명작’**들입니다. 아키텍트의 역할은 이들의 고유한 설계 철학(Philosophy)을 이해하고 적재적소에 배치하는 것입니다.\nHeavy Batch (Tez): 대용량 데이터의 안정적 처리가 필요한 ETL 작업에는, 화려함보다 **‘경제성’**과 **‘정밀 제어’**가 중요합니다. 2,000억 건의 데이터를 디스크 기반으로 묵묵히 처리해 내는 Tez의 ‘지구력’은 대규모 배치 처리에 가장 적합한 덕목입니다.\nAd-hoc Analysis (Trino): 빠른 의사결정이 필요한 분석 업무에는, 쿼리 응답 속도(Latency)에 목숨을 건 Trino가 최고의 파트너입니다.\nAdvanced Analytics (Spark): 머신러닝(ML)이나 스트리밍처럼 메모리를 많이 쓰더라도 빠른 반복 계산이 필요한 영역에서는, Spark의 강력한 퍼포먼스가 빛을 발합니다.\n모든 엔진은 각자의 무대에서는 주인공입니다. 아키텍트는 그들을 한 무대에 억지로 구겨 넣는 것이 아니라, 각자가 가장 빛날 수 있는 무대(Layer)를 만들어주는 연출가여야 합니다.","surgery-3-인재의-재정의--시스템과-교육의-혁신#Surgery 3. 인재의 재정의 : \u0026ldquo;시스템과 교육의 혁신\u0026rdquo;":"[진단 1: 스펙 인플레이션과 ‘게으른 검증’] 우리는 종종 “스펙은 화려한데 일은 못 하는 엔지니어\"를 마주합니다. 하지만 이것은 지원자들의 잘못이 아닙니다. 글로벌 빅테크의 채용 방식을 껍데기만 베껴 온 기업들의 ‘게으른 검증 시스템’이 만든 비극입니다.\n많은 기업이 빅테크가 ‘왜’ 그런 면접을 보는지 근본적인 의도는 파악하지 못한 채, 단순히 코딩 테스트 난이도만 높이는 식으로 형식을 답습합니다. 그 결과, 정해진 알고리즘 문제 풀이(LeetCode)는 기계처럼 잘하지만, 정작 실전 데이터 파이프라인의 병목은 찾지 못하는 **‘시험형 인재’**만 양산하고 있습니다.\n[진단 2: 잃어버린 기술력의 시대] 여기에 더해 **‘기계적 형평성’**이라는 이름 아래 엔지니어의 차별성을 지워왔습니다. 압도적인 퍼포먼스를 내는 엔지니어와 단순히 자리를 지키는 엔지니어의 보상이 비슷해지면서, 치열하게 기술적 **‘깊이(Depth)’**를 파고드는 것은 손해 보는 장사가 되었습니다. 진짜 실력자들은 떠나고, 남은 자리엔 ‘정치’와 ‘스펙’으로 무장한 사람들만 남게 된 것입니다.\n[처방: 보상을 넘어선, 사회적 시스템의 대전환] 이 문제를 해결하기 위해서는 개별 기업의 보상 정책을 넘어선, 사회적 시스템의 대수술이 필요합니다.\n교육의 혁신 (From Tools to Principles): 현재의 코딩 교육은 ‘도구 사용법’을 가르치는 데 급급합니다. 유행하는 프레임워크 이전에 컴퓨터 구조와 메모리 관리 등 **‘근본 원리’**를 가르쳐야 합니다. 화려한 문법보다 **‘왜(Why)’**를 질문하는 엔지니어를 길러내는 것이 교육의 목표가 되어야 합니다.\n사회적 인식의 개선 (Recognition): 엔지니어를 단순히 ‘기능 구현자’나 ‘전산실 관리자’로 보는 낡은 인식을 버려야 합니다. 데이터 시대의 엔지니어는 건물을 짓는 건축가(Architect)와 같으며, 기업의 자산을 설계하고 지키는 핵심 인력이라는 사회적 합의가 필요합니다.\n합당한 대우와 동기부여 (Compensation): 이러한 인식 개선 위에서, 실력에 따른 파격적인 보상은 자연스러운 귀결이어야 합니다. 최고의 인재들이 의대나 로스쿨이 아닌, ‘데이터 엔지니어링’에 인생을 걸고 싶게 만들어야 합니다.\n결국 기업과 사회가 ‘진짜 실력’을 알아보고 대우할 때, 비로소 우리 곁에 수많은 ‘Surgical Architect’들이 탄생할 것입니다."},"title":"클라우드 비용 효율화 : 지속 가능한 성장을 위한 3가지 대수술: 기술적 최적화가 경영의 효율성으로 이어지는 길"},"/blog/data_engineering/tez_optimization/":{"data":{"":"","1-환자-차트-patient-chart--이게-돌아간다고#1. 환자 차트 (Patient Chart) : \u0026ldquo;이게 돌아간다고?\u0026rdquo;":"대부분의 엔지니어는 이 스펙을 듣는 순간 고개를 저을 것입니다.\n데이터 규모: 2000억 건 (비정형 텍스트 로그 포함) 복잡도: 100-way Join (Data Mart 생성) 리소스: 1120 vCore, Total 2TB Memory 엔진: Hive on Tez 일반적인 처방(Diagnosis)이라면 이렇게 말했을 겁니다. “컨테이너당 16GB 할당하고, 노드 2배로 늘리세요. 안 그러면 OOM 납니다.”\n하지만 저는 정반대의 처방을 내렸습니다. 컨테이너 사이즈 2GB. 힌트(Hint) 없음. 실행 옵션(Execute Option) 없음\n이것은 무모한 도박이 아니었습니다. 철저한 진단 끝에 내린 **정밀 수술(Surgery)**이었습니다.","2-오진misdiagnosis--메모리는-죄가-없다#2. 오진(Misdiagnosis) : 메모리는 죄가 없다":"처음엔 저도 두려웠습니다. “혹시 터지면 어떡하지?“라는 마음에 관습적으로 4GB를 할당했었습니다. 하지만 모니터링 툴(Dr. Elephant 등)을 통해 시스템의 비명을 자세히 들어보니, 진짜 병명은 메모리 부족이 아니었습니다.\n범인은 ‘500자 정규식’ (CPU Bound) 로그를 파싱 하는 Mapper 단계가 병목이었습니다. 원인은 무려 **500자에 달하는 거대한 정규식(Regex)**이었습니다. 이 무거운 연산을 처리하느라 CPU가 비명을 지르고 있는데, 우리는 엉뚱하게 메모리(RAM)만 더 주고 있었던 것입니다. 배 아픈 환자에게 소화제 대신 반창고를 붙이고 있었던 꼴이죠.","3-집도-the-surgery--엔진을-믿지-말고-데이터를-믿어라#3. 집도 (The Surgery) : 엔진을 믿지 말고, 데이터를 믿어라":"저는 Tez 엔진의 자동화 기능에 의존하는 것을 멈췄습니다. 엔진은 마법사가 아닙니다.\n(1) 블랙박스를 열다 : 수동 데이터 분포 분석\nShuffle Skew는 블랙박스입니다. 화면은 멈춰있고, 로그는 침묵합니다. 저는 이 블랙박스를 열기 위해 원천 데이터를 일일이 SQL로 조회하여 분포를 확인했습니다. 그리고 데이터가 쏠리는(Skew) 키 값들을 찾아내, SQL 레벨에서 직접 분산 로직을 심었습니다.\n(2) Delete 키를 누르다 : Back to Basic\n가장 중요한 수술은 더하는 것이 아니라 빼는 것이었습니다. 불안감 때문에 덕지덕지 붙였던 메모리 설정, 병렬 처리 옵션들을 전부 지웠습니다(Delete).\nHortonworks HDP Container Size (Default) = 2GB\n놀랍게도, 순정 상태로 돌아가자 Tez는 본래의 성능을 발휘하기 시작했습니다. 1120 vCore라는 한정된 자원 안에서, 2GB의 가벼운 컨테이너들은 **엄청난 밀도(Density)**로 재사용(Reuse)되며 2000억 건의 데이터를 씹어먹기 시작했습니다.","4-경과-recovery--120분의-기적#4. 경과 (Recovery) : 120분의 기적":"수술 결과는 데이터가 증명했습니다.\n수행 시간: 2000억 건 처리 120분 (2시간) 완료. 안정성: 수술 이후 3개월간 에러율 0%. 효율: 초기 Stage에서는 리소스를 100% 사용하여 폭발적으로 처리하고, 이후 단계에서는 유려하게 흘려보냄. 남들이 “부족하다\"고 했던 2GB는, 사실 시스템이 필요로 하는 최적의 정량이었습니다. 우리가 그동안 낭비했던 수 테라바이트의 메모리는 시스템의 한계가 아니라, 엔지니어의 **공포심(Fear)**이 만들어낸 거품이었습니다.","5-결론--최적화의-끝은-순정이다#5. 결론 : 최적화의 끝은 \u0026lsquo;순정\u0026rsquo;이다":"많은 분들이 2000억 건 처리에 대한 “특별한 비법\"을 묻습니다. 하지만 저는 드릴 말씀이 없습니다.\n저는 그저 데이터를 뜯어보고(Analyze), 쿼리를 다듬고(Refine), 불필요한 설정을 지웠을(Delete) 뿐입니다. 엔지니어링의 정점은 무엇을 더하는 것이 아니라, 불필요한 것을 걷어내는 데 있습니다.","executive-summary#Executive Summary":"Just Logic"},"title":"[Tez] 2000억 건 로그 처리, 힌트는 필요 없다 : 2GB 컨테이너의 승리"},"/docs/":{"data":{"":""},"title":"Documentation"},"/docs/computer_science/":{"data":{"":""},"title":"Computer Science"},"/docs/data_analysis/":{"data":{"":""},"title":"Data Analysis"},"/docs/data_engineering/":{"data":{"":""},"title":"Data Engineering"},"/docs/data_engineering/data_warehouse/":{"data":{"":"Data Warehouse"},"title":"Data Warehouse"},"/docs/data_engineering/etl/":{"data":{"":"Extract Transform Load"},"title":"ETL"},"/docs/er_model/":{"data":{"":""},"title":"ER Modeling"},"/docs/greetings/":{"data":{"":""},"title":"Greetings"},"/docs/md_model/":{"data":{"":""},"title":"MD Modeling"},"/docs/software_engineering/":{"data":{"":""},"title":"Software Engineering"}}